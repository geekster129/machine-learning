{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A type of supervised learning to predict a value in a continuous dataset with the following hypothesis function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "h(x) =  \\theta_1x + \\theta_0\n",
    "\\end{equation*}\n",
    "\n",
    "where h(x) is the output value,\n",
    "x is the input value, ${\\theta_0}$ and ${\\theta_1}$ is the parameter that we need to find in order draw a line that best fit the datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "Cost function is used as a measurement to determine how good the line fits the datasets, if we are given any arbitrary parameters a and b\n",
    "\n",
    "The cost function that we will be using is called Mean Square Error (MSE). This function basically will get the average of the total sum of the square difference between the predicted value and the actual value. \n",
    "\n",
    "Basically, what we want to achieve is to get the smallest MSE value possible because that will give us the most accurate prediction\n",
    "\n",
    "### Calculating the loss for one variable linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a set of 12 data points:    \n",
    "  \n",
    "*taken from Andrew Ng's Machine Learning course on Coursera\n",
    "\n",
    "| ${x}$ | ${y}$  |\n",
    "|-------|----|\n",
    "| 1     |-890|\n",
    "| 2     |-1411|\n",
    "| 2     |-1560|\n",
    "| 3     |-2220|\n",
    "| 3     |-2091|\n",
    "| 4     |-2878|\n",
    "| 5     |-3537|\n",
    "| 6     |-3268|\n",
    "| 6     |-3920|\n",
    "| 6     |-4163|\n",
    "| 8     |-5471|\n",
    "| 10    |-5157|\n",
    "\n",
    "and we have 4 possible values of our parameters ${\\theta_0}$ and ${\\theta_1}$:\n",
    "\n",
    "| ${\\theta_0}$ | ${\\theta_1}$ | Model |\n",
    "|-------|----|----|\n",
    "| -1780     |530.9| ${y}$ = -1780${x}$ + 530.9\n",
    "| -1780     |-530.9| ${y}$ = -1780${x}$ - 530.9\n",
    "| -569.6     |530.9| ${y}$ = -569.6${x}$ + 530.9\n",
    "| -569.6     |-530.9| ${y}$ = -569.6${x}$ - 530.9\n",
    "\n",
    "So, the objective here is to determine which ${\\theta_0}$ and ${\\theta_1}$ will be the optimal value for our linear\n",
    "regression model to predict the y value, given x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python script to calculate MSE (Mean Square Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(data, theta0, theta1):\n",
    "    \n",
    "    # Get the SSE by adding up the square of the difference between prediction value\n",
    "    # and the actual value, this will be fed into MSE calculation\n",
    "    sse = 0\n",
    "    for i in range(len(data)):\n",
    "        pred_val = data[i][0] * theta0 + theta1\n",
    "        sq_diff = (data[i][1] - pred_val) ** 2\n",
    "        sse = sse + sq_diff\n",
    "    \n",
    "    # Get the MSE (Mean Square Error) or simply the loss \n",
    "    mse = sse / (2 * len(data)) \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's calculate the loss for different values of ${\\theta_0}$ and ${\\theta_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for theta0= -1780  and theta1= 530.9 is  2356033743.12\n",
      "MSE for theta0= -1780  and theta1= -530.9 is  3160207085.52\n",
      "MSE for theta0= -569.6  and theta1= 530.9 is  71346612.23999998\n",
      "MSE for theta0= -569.6  and theta1= -530.9 is  11863726.799999999\n"
     ]
    }
   ],
   "source": [
    "data = [[1,-890],\n",
    "        [2, -1411], \n",
    "        [2, -1560],\n",
    "        [3, -2220],\n",
    "        [3, -2091],\n",
    "        [4, -2878],\n",
    "        [5,-3537],\n",
    "        [6, -3268],\n",
    "        [6, -3920],\n",
    "        [6, -4163],\n",
    "        [8,-5471],\n",
    "        [10,-5157]]\n",
    "\n",
    "theta_arr = [[-1780,530.9],\n",
    "             [-1780,-530.9],\n",
    "             [-569.6,530.9],\n",
    "             [-569.6,-530.9]]\n",
    "\n",
    "for x in range(len(theta_arr)):\n",
    "    theta0 = theta_arr[x][0]\n",
    "    theta1 = theta_arr[x][1]\n",
    "    print(\"MSE for theta0=\",theta0,\" and theta1=\",theta1,\"is \", calc_mse(data, theta0, theta1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "To recap on the MSE explanation in the beginning of this document, we want to achive the smallest MSE value in order to have a function that can give us the most accurate prediction of the next unknown y, given a new x value.\n",
    "\n",
    "The minimal loss (or the smallest MSE value) that we can get with the 4 different ${\\theta_0}$ and ${\\theta_1}$ values is 11863726.799999999\n",
    "\n",
    "So in other words, the suitable linear regression function would be:\n",
    "\n",
    "\\begin{equation*} y = -569.6x -530.9\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward\n",
    "\n",
    "You may be asking: what does this have to do with machine learning? Finding the loss value (in this case, MSE) is one of the steps in a machine learning optimization process to minimize the error in the prediction function.\n",
    "\n",
    "A machine learning task will perform the following 3 steps\n",
    "\n",
    "1. PREDICT the value with a hypothesis function using initial parameters ${\\theta_0}$ and ${\\theta_1}$\n",
    "2. EVALUATE using the cost function to determine how inaccurate the prediction by comparing prediction and actual value\n",
    "3. TRAIN (gradually fine-tune the ${\\theta}$) parameters with the guide of the cost fucntion until you eventually get the smallest loss value\n",
    "4. Rinse and repeat.\n",
    "\n",
    "In the next section, we will look into what's called Parameterized Learning. It is the step of training the machine to repetitively find out what is the best values of ${\\theta_0}$ and ${\\theta_1}$ which will give the smallest loss value, and the training algorithm used is called the Gradient Descent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
